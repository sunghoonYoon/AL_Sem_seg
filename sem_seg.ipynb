{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original code and checkpoints by Hang Zhang\n",
    "# https://github.com/zhanghang1989/PyTorch-Encoding\n",
    "\n",
    "import torchvision.models.resnet\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import zipfile\n",
    "import shutil\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torch.nn as nn\n",
    "try:\n",
    "    from urllib import urlretrieve\n",
    "except ImportError:\n",
    "    from urllib.request import urlretrieve\n",
    "\n",
    "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
    "           'resnet152', 'BasicBlock', 'Bottleneck']\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"3x3 convolution with padding\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    \"\"\"ResNet BasicBlock\n",
    "    \"\"\"\n",
    "    expansion = 1\n",
    "    def __init__(self, inplanes, planes, stride=1, dilation=1, downsample=None, previous_dilation=1,\n",
    "                 norm_layer=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=dilation, dilation=dilation, bias=False)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1,\n",
    "                               padding=previous_dilation, dilation=previous_dilation, bias=False)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    \"\"\"ResNet Bottleneck\n",
    "    \"\"\"\n",
    "    # pylint: disable=unused-argument\n",
    "    expansion = 4\n",
    "    def __init__(self, inplanes, planes, stride=1, dilation=1,\n",
    "                 downsample=None, previous_dilation=1, norm_layer=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            planes, planes, kernel_size=3, stride=stride,\n",
    "            padding=dilation, dilation=dilation, bias=False)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = norm_layer(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.dilation = dilation\n",
    "        self.stride = stride\n",
    "\n",
    "    def _sum_each(self, x, y):\n",
    "        assert(len(x) == len(y))\n",
    "        z = []\n",
    "        for i in range(len(x)):\n",
    "            z.append(x[i]+y[i])\n",
    "        return z\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    \"\"\"Dilated Pre-trained ResNet Model, which preduces the stride of 8 featuremaps at conv5.\n",
    "\n",
    "    Reference:\n",
    "        - He, Kaiming, et al. \"Deep residual learning for image recognition.\" CVPR. 2016.\n",
    "        - Yu, Fisher, and Vladlen Koltun. \"Multi-scale context aggregation by dilated convolutions.\"\n",
    "    \"\"\"\n",
    "    # pylint: disable=unused-variable\n",
    "    def __init__(self, block, layers, num_classes=1000, dilated=True, multi_grid=False,\n",
    "                 deep_base=True, norm_layer=nn.BatchNorm2d):\n",
    "        self.inplanes = 128 if deep_base else 64\n",
    "        super(ResNet, self).__init__()\n",
    "        if deep_base:\n",
    "            self.conv1 = nn.Sequential(\n",
    "                nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "                norm_layer(64),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                norm_layer(64),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            )\n",
    "        else:\n",
    "            self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                                   bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], norm_layer=norm_layer)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, norm_layer=norm_layer)\n",
    "        if dilated:\n",
    "            self.layer3 = self._make_layer(block, 256, layers[2], stride=1,\n",
    "                                           dilation=2, norm_layer=norm_layer)\n",
    "            if multi_grid:\n",
    "                self.layer4 = self._make_layer(block, 512, layers[3], stride=1,\n",
    "                                               dilation=4, norm_layer=norm_layer,\n",
    "                                               multi_grid=True)\n",
    "            else:\n",
    "                self.layer4 = self._make_layer(block, 512, layers[3], stride=1,\n",
    "                                               dilation=4, norm_layer=norm_layer)\n",
    "        else:\n",
    "            self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                           norm_layer=norm_layer)\n",
    "            self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                           norm_layer=norm_layer)\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, norm_layer):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilation=1, norm_layer=None, multi_grid=False):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        multi_dilations = [4, 8, 16]\n",
    "        if multi_grid:\n",
    "            layers.append(block(self.inplanes, planes, stride, dilation=multi_dilations[0],\n",
    "                                downsample=downsample, previous_dilation=dilation, norm_layer=norm_layer))\n",
    "        elif dilation == 1 or dilation == 2:\n",
    "            layers.append(block(self.inplanes, planes, stride, dilation=1,\n",
    "                                downsample=downsample, previous_dilation=dilation, norm_layer=norm_layer))\n",
    "        elif dilation == 4:\n",
    "            layers.append(block(self.inplanes, planes, stride, dilation=2,\n",
    "                                downsample=downsample, previous_dilation=dilation, norm_layer=norm_layer))\n",
    "        else:\n",
    "            raise RuntimeError(\"=> unknown dilation size: {}\".format(dilation))\n",
    "\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            if multi_grid:\n",
    "                layers.append(block(self.inplanes, planes, dilation=multi_dilations[i],\n",
    "                                    previous_dilation=dilation, norm_layer=norm_layer))\n",
    "            else:\n",
    "                layers.append(block(self.inplanes, planes, dilation=dilation, previous_dilation=dilation,\n",
    "                                    norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "def resnet50(pretrained=False, root='./pretrained', **kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "\n",
    "    if pretrained:\n",
    "        model.load_state_dict(torch.load(\"./res/resnet50s-a75c83cf.pth\"))\n",
    "        # model.load_state_dict(load_url(model_urls['resnet50'], model_dir=root))\n",
    "        # model.load_state_dict((torchvision.models.resnet.load_state_dict_from_url(model_urls['resnet50'],progress=True)),strict=False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design Segmentation Network (PSPNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "from itertools import chain\n",
    "\n",
    "class _PSPModule(nn.Module):\n",
    "    def __init__(self, in_channels, bin_sizes, norm_layer): #bin_sizes= [1,2,3,6]\n",
    "        super(_PSPModule, self).__init__()\n",
    "        out_channels = in_channels // len(bin_sizes)\n",
    "        self.stages = nn.ModuleList([self._make_stages(in_channels, out_channels, b_s, norm_layer) \n",
    "                                                        for b_s in bin_sizes])\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(in_channels+(out_channels * len(bin_sizes)), out_channels, \n",
    "                                    kernel_size=3, padding=1, bias=False),\n",
    "            norm_layer(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(0.1)\n",
    "        )\n",
    "\n",
    "    def _make_stages(self, in_channels, out_channels, bin_sz, norm_layer):\n",
    "        prior = nn.AdaptiveAvgPool2d(output_size=bin_sz)\n",
    "        conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        bn = norm_layer(out_channels)\n",
    "        relu = nn.ReLU(inplace=True)\n",
    "        return nn.Sequential(prior, conv, bn, relu)\n",
    "    \n",
    "    def forward(self, features):\n",
    "        h, w = features.size()[2], features.size()[3]\n",
    "        pyramids = [features]\n",
    "        pyramids.extend([F.interpolate(stage(features), size=(h, w), mode='bilinear', \n",
    "                                        align_corners=True) for stage in self.stages])\n",
    "        output = self.bottleneck(torch.cat(pyramids, dim=1))\n",
    "        return output\n",
    "\n",
    "\n",
    "class PSPNet(nn.Module):\n",
    "    def __init__(self, num_classes, in_channels=3, backbone='resnet50'):\n",
    "        super(PSPNet, self).__init__()\n",
    "        norm_layer = nn.BatchNorm2d\n",
    "        model = resnet50(norm_layer=norm_layer)#getattr(resnet, backbone)(pretrained, norm_layer=norm_layer)\n",
    "        m_out_sz = model.fc.in_features\n",
    "\n",
    "        self.initial = nn.Sequential(*list(model.children())[:4])\n",
    "        if in_channels != 3:\n",
    "            self.initial[0] = nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.initial = nn.Sequential(*self.initial)\n",
    "        \n",
    "        self.layer1 = model.layer1\n",
    "        self.layer2 = model.layer2\n",
    "        self.layer3 = model.layer3\n",
    "        self.layer4 = model.layer4\n",
    "\n",
    "        self.master_branch = nn.Sequential(\n",
    "            _PSPModule(m_out_sz, bin_sizes=[1, 2, 3, 6], norm_layer=norm_layer),\n",
    "            nn.Conv2d(m_out_sz//4, num_classes, kernel_size=1)\n",
    "        )\n",
    "\n",
    "        self.auxiliary_branch = nn.Sequential(\n",
    "            nn.Conv2d(m_out_sz//2, m_out_sz//4, kernel_size=3, padding=1, bias=False),\n",
    "            norm_layer(m_out_sz//4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(0.1),\n",
    "            nn.Conv2d(m_out_sz//4, num_classes, kernel_size=1)\n",
    "        )\n",
    "\n",
    "       \n",
    "\n",
    "    def forward(self, x):\n",
    "        input_size = (x.size()[2], x.size()[3])\n",
    "        x = self.initial(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x_aux = self.layer3(x)\n",
    "        x = self.layer4(x_aux)\n",
    "\n",
    "        output = self.master_branch(x)\n",
    "        output = F.interpolate(output, size=input_size, mode='bilinear')\n",
    "        output = output[:, :, :input_size[0], :input_size[1]]\n",
    "\n",
    "        if self.training and self.use_aux:\n",
    "            aux = self.auxiliary_branch(x_aux)\n",
    "            aux = F.interpolate(aux, size=input_size, mode='bilinear')\n",
    "            aux = aux[:, :, :input_size[0], :input_size[1]]\n",
    "            return output, aux\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = PSPNet(num_classes=21)\n",
    "\n",
    "assert torch.cuda.is_available(), 'change your runtime to GPU' \n",
    "\n",
    "state_dict = torch.load(\"/content/drive/MyDrive/TA_segmentation/P_best_0511_76.7.pth\")\n",
    "\n",
    "net.load_state_dict(state_dict)\n",
    "net.eval()\n",
    "net.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voc_palette(label):\n",
    "\tm = label.astype(np.uint8)\n",
    "\tr,c = m.shape\n",
    "\tcmap = np.zeros((r,c,3), dtype=np.uint8)\n",
    "\tcmap[:,:,0] = (m&1)<<7 | (m&8)<<3\n",
    "\tcmap[:,:,1] = (m&2)<<6 | (m&16)<<2\n",
    "\tcmap[:,:,2] = (m&4)<<5\n",
    "\tcmap[m==255] = [255,255,255]\n",
    "\treturn cmap\n",
    "\n",
    "def denorm(img):\n",
    "    # ImageNet statistics\n",
    "    mean_img = [0.485, 0.456, 0.406]\n",
    "    std_img = [0.229, 0.224, 0.225]\n",
    "\n",
    "    tf_denorm = transforms.Normalize(mean = [-mean_img[0] / std_img[0], -mean_img[1] / std_img[1], -mean_img[2] / std_img[2]],\n",
    "                                     std = [1 / std_img[0], 1 / std_img[1], 1 / std_img[2]])\n",
    "\n",
    "    return tf_denorm(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get prediction from Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################YOUR OWN IMPLEMENTATION######################\n",
    "\n",
    "#Use transforms.ToTensor\n",
    "#Use transforms.Normalize\n",
    "\n",
    "#Read Image \n",
    "\n",
    "#normalize Image\n",
    "#extend dimentsion (-,-,-,-) 4ch\n",
    "#(Resize image if needed)\n",
    "\n",
    "#get Network output => logits\n",
    "#make logit to probability \n",
    "#get the maximum argument (argmax) = prediction\n",
    "#convert the prediction into color (Useing voc_palette function)\n",
    "\n",
    "#use plt function to visualize (alpha = 0.6)\n",
    "#and save the results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('wsss_ksj')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f0c8f0cdee1354878dc5d710d6113d8ed82e602ef56b0871a36b2b2c0d87e6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
